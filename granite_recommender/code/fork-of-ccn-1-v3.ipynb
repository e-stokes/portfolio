{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "from keras.models import Sequential\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating image size parameter\n",
    "img_size = 48\n",
    "\n",
    "# creating batch size variable\n",
    "batch = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting earlystopping\n",
    "early = EarlyStopping(monitor = 'val_loss',\n",
    "              mode = 'min',\n",
    "              patience = 3, \n",
    "              restore_best_weights = True)\n",
    "\n",
    "# setting modelcheckpoint\n",
    "check = ModelCheckpoint('./m_checkpoint',\n",
    "               monitor = 'val_loss',\n",
    "               save_best_only = True,\n",
    "               mode = 'min')\n",
    "\n",
    "# creating list for callbacks\n",
    "call_list = [early, check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 images belonging to 6 classes.\n",
      "Found 191 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# loading data from directory\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range = 20,\n",
    "        validation_split = .3,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        '/kaggle/input/granite_slabs/granite_slabs',\n",
    "        subset = 'training',\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch,\n",
    "        color_mode = 'rgb',\n",
    "        class_mode= 'categorical')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        '/kaggle/input/granite_slabs/granite_slabs',\n",
    "        subset = 'validation',\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch,\n",
    "        class_mode= 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model\n",
    "model = Sequential()\n",
    "\n",
    "# input Convolutional layer\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "\n",
    "\n",
    "\n",
    "# # Adding 1st conv layer\n",
    "model.add(Conv2D(64,\n",
    "                kernel_size = 3,\n",
    "                activation = 'relu',\n",
    "                kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# adding pooling\n",
    "model.add(MaxPooling2D(pool_size = 3))\n",
    "\n",
    "# adding dropout\n",
    "model.add(Dropout(rate = .5))\n",
    "\n",
    "# Adding 2nd conv layer\n",
    "model.add(Conv2D(128,\n",
    "                 kernel_size = 3,\n",
    "                 activation = 'relu',\n",
    "                 kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 2nd max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "# # adding dropout\n",
    "# model.add(Dropout(rate = .25))\n",
    "          \n",
    "# # Adding 3rd conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=3,\n",
    "#                  activation='relu',\n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 3rd max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "# # Adding 4th conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=3,\n",
    "#                  activation='relu', \n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 4th max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "# # Adding 5th conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=1,\n",
    "#                  activation='relu',\n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 5th max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "# # Adding 6th conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=1,\n",
    "#                  activation='relu',\n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# Adding 6th max pooling\n",
    "model.add(MaxPooling2D(pool_size= 4))\n",
    "\n",
    "# adding dropout\n",
    "model.add(Dropout(rate = .25))\n",
    "\n",
    "# # Adding 7th conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=1,\n",
    "#                  activation='relu',\n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 7th max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# model.add(Dense(256,\n",
    "#                activation = 'relu'))\n",
    "# model.add(Dense(128,\n",
    "#                activation = 'relu'))\n",
    "# model.add(Dense(64,\n",
    "#                activation = 'relu'))\n",
    "model.add(Dense(128,\n",
    "               activation = 'relu',\n",
    "               kernel_regularizer = regularizers.l2(.01)))\n",
    "model.add(layers.Dense(6, activation = 'softmax',\n",
    "                      kernel_regularizer = regularizers.l2(.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 260,934\n",
      "Trainable params: 260,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# checking summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "50/50 [==============================] - 790s 16s/step - loss: 3.8511 - acc: 0.1904 - val_loss: 2.5979 - val_acc: 0.3194\n",
      "Epoch 2/12\n",
      "50/50 [==============================] - 779s 16s/step - loss: 2.1395 - acc: 0.3047 - val_loss: 1.9038 - val_acc: 0.4005\n",
      "Epoch 3/12\n",
      "50/50 [==============================] - 787s 16s/step - loss: 1.6923 - acc: 0.4014 - val_loss: 1.8495 - val_acc: 0.4437\n",
      "Epoch 4/12\n",
      "50/50 [==============================] - 780s 16s/step - loss: 1.4911 - acc: 0.4939 - val_loss: 1.6447 - val_acc: 0.4398\n",
      "Epoch 5/12\n",
      "50/50 [==============================] - 796s 16s/step - loss: 1.4299 - acc: 0.5356 - val_loss: 1.6762 - val_acc: 0.4542\n",
      "Epoch 6/12\n",
      "50/50 [==============================] - 794s 16s/step - loss: 1.3885 - acc: 0.5152 - val_loss: 1.7202 - val_acc: 0.3508\n",
      "Epoch 7/12\n",
      "50/50 [==============================] - 786s 16s/step - loss: 1.3794 - acc: 0.5361 - val_loss: 1.5206 - val_acc: 0.4516\n",
      "Epoch 8/12\n",
      "50/50 [==============================] - 791s 16s/step - loss: 1.2757 - acc: 0.5869 - val_loss: 1.5292 - val_acc: 0.4660\n",
      "Epoch 9/12\n",
      "50/50 [==============================] - 787s 16s/step - loss: 1.2608 - acc: 0.5765 - val_loss: 1.5247 - val_acc: 0.4725\n",
      "Epoch 10/12\n",
      "50/50 [==============================] - 794s 16s/step - loss: 1.2801 - acc: 0.5516 - val_loss: 1.5896 - val_acc: 0.3979\n"
     ]
    }
   ],
   "source": [
    "# fitting model\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=50,\n",
    "        epochs=12,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=12,\n",
    "        workers = -1,\n",
    "        verbose = 1,\n",
    "        callbacks = call_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_extractor = Model(model.input, outputs=model.get_layer(\"dense_2\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 260,934\n",
      "Trainable params: 260,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feat_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "# model.save('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 65s 13s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.287302693953881, 0.6076923076923076]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model performance\n",
    "model.evaluate_generator(train_generator, steps = 5, workers = -1, verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
