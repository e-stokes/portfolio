{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "from keras.models import Sequential\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import layers\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/Users/eric/Desktop/gramaco_capstone/all_slabs/'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating image size variable\n",
    "img_size = 224\n",
    "\n",
    "# creating batch size variable\n",
    "batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting earlystopping\n",
    "early = EarlyStopping(monitor = 'val_loss',\n",
    "              mode = 'min',\n",
    "              patience = 3, \n",
    "              restore_best_weights = True)\n",
    "\n",
    "# setting modelcheckpoint\n",
    "check = ModelCheckpoint('./m_checkpoint',\n",
    "               monitor = 'val_loss',\n",
    "               save_best_only = True,\n",
    "               mode = 'min')\n",
    "\n",
    "# creating list for callbacks\n",
    "call_list = [early, check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 451 images belonging to 1 classes.\n",
      "Found 192 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# image augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range = 20,\n",
    "        validation_split = .3,\n",
    "        horizontal_flip=True)\n",
    "# loading data from directory\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        '/Users/eric/Desktop/gramaco_capstone/all_slabs/',\n",
    "        subset = 'training',\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch,\n",
    "        color_mode = 'rgb',\n",
    "        class_mode= None)\n",
    "\n",
    "# validation generator to run validations \n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        '/Users/eric/Desktop/gramaco_capstone/all_slabs/',\n",
    "        subset = 'validation',\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch,\n",
    "        class_mode= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/dsi/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# loading saved model\n",
    "model = VGG16(weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# checking summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following lines would only be run to train the model on data, however the model is already trained\n",
    "# Do NOT run the following two cells of code (commented cells)\n",
    "\n",
    "# fitting model\n",
    "# history = model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=50,\n",
    "#         epochs=12,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=12,\n",
    "#         workers = -1,\n",
    "#         verbose = 1,\n",
    "#         callbacks = call_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model performance on 20 steps\n",
    "# model.evaluate_generator(train_generator, steps = 20, workers = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating feature extractor\n",
    "feat_extractor = Model(model.input, outputs=model.get_layer(\"fc2\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting summary of features\n",
    "feat_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluating model performance on 5 steps\n",
    "# model.evaluate_generator(train_generator, steps = 5, workers = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of images\n",
    "path = '/Users/eric/Desktop/gramaco_capstone/test_slabs/'\n",
    "\n",
    "# Loading testing images to use for recommendations, filters by file type\n",
    "products = [path + x for x in os.listdir(path) if \"jpg\" or \"JPG\" or 'png' or 'jpeg' in x]\n",
    "\n",
    "# prints out number of product images\n",
    "print(\"number of products:\",len(products))\n",
    "\n",
    "# load an image in Python Image Library (PIL) format\n",
    "image = load_img(products[0], target_size=(img_size, img_size))\n",
    "\n",
    "# plots images\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "# gets filename from path only\n",
    "p_name = os.path.basename(str(products))\n",
    "\n",
    "# prints out product image\n",
    "print(f\"{p_name} loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the images and prepare them for feeding into the CNN\n",
    "importedImages = [] # empty list to append\n",
    "\n",
    "for p in products: # loop to iterate through each product in file path\n",
    "    filename = p\n",
    "    image = load_img(filename, target_size=(img_size, img_size)) \n",
    "    numpy_image = img_to_array(image) # converting image to array\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0) # adding dimensions to images with expand_dims\n",
    "\n",
    "    importedImages.append(image_batch) # appending the empty list\n",
    "\n",
    "images = np.vstack(importedImages) # reconstructing images from array \n",
    "\n",
    "processed_imgs = preprocess_input(images.copy())\n",
    "\n",
    "# extract the images features\n",
    "imgs_features = feat_extractor.predict(processed_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve the most similar products for a given one\n",
    "def recommender(product):\n",
    "\n",
    "    # compute cosine similarities between images\n",
    "    cosine = cosine_similarity(imgs_features)\n",
    "\n",
    "    # creates a dataframe of the cosine similarites\n",
    "    cosine_df = pd.DataFrame(cosine, columns=products, index=products)\n",
    "    \n",
    "    # number of recommendations\n",
    "    sim_images = 5\n",
    "    \n",
    "    # name of product without entire directory\n",
    "    p_name = os.path.basename(str(product))\n",
    "    \n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(f\"Selected {p_name}:\")\n",
    "\n",
    "    # Loads images and plots them\n",
    "    image = load_img(product, target_size=(img_size, img_size))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(f\"Recommended products based on {p_name}:\")\n",
    "    \n",
    "    # Using cosine data frame to extract recommended images\n",
    "    recommend_imgs = cosine_df[product].sort_values(ascending=False)[1:sim_images+1].index\n",
    "    \n",
    "    # Using cosine data frame to extract the scores for each recommendation\n",
    "    recommend_scores = cosine_df[product].sort_values(ascending=False)[1:sim_images+1]\n",
    "    \n",
    "    # Loop through the data frames and load the recommended image\n",
    "    for i in range(0,len(recommend_imgs)):\n",
    "        image = load_img(recommend_imgs[i], target_size=(img_size, img_size))\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        \n",
    "        # recommended product name without entire directory\n",
    "        rec_name = os.path.basename(str(recommend_imgs[i]))\n",
    "        \n",
    "        # Items to be printed to screen\n",
    "        print(f\"Recommended Product: {rec_name}\")\n",
    "        print(f\"Recommendation Score: {recommend_scores[i]}\")\n",
    "        print(\"-----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recommender(products[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (dsi)",
   "language": "python",
   "name": "pycharm-32585468"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
