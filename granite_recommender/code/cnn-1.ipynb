{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "from keras.models import Sequential\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting earlystopping\n",
    "early = EarlyStopping(monitor = 'val_loss',\n",
    "              mode = 'min',\n",
    "              patience = 3, \n",
    "              restore_best_weights = True)\n",
    "\n",
    "# setting modelcheckpoint\n",
    "check = ModelCheckpoint('./m_checkpoint',\n",
    "               monitor = 'val_loss',\n",
    "               save_best_only = True,\n",
    "               mode = 'min')\n",
    "\n",
    "# creating list for callbacks\n",
    "call_list = [early, check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 images belonging to 6 classes.\n",
      "Found 191 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# loading data from directory\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range = 20,\n",
    "        validation_split = .3,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        '/kaggle/input/granite_slabs/granite_slabs',\n",
    "        subset = 'training',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        color_mode = 'rgb',\n",
    "        class_mode= 'categorical')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        '/kaggle/input/granite_slabs/granite_slabs',\n",
    "        subset = 'validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode= 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating model\n",
    "model = Sequential()\n",
    "\n",
    "# input Convolutional layer\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "\n",
    "\n",
    "\n",
    "# # Adding 1st conv layer\n",
    "model.add(Conv2D(128,\n",
    "                kernel_size = 3,\n",
    "                activation = 'relu',\n",
    "                kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # adding pooling\n",
    "# model.add(MaxPooling2D(pool_size = 3))\n",
    "\n",
    "# # adding dropout\n",
    "# # model.add(Dropout(rate = .5))\n",
    "\n",
    "# # Adding 2nd conv layer\n",
    "# model.add(Conv2D(128,\n",
    "#                  kernel_size = 3,\n",
    "#                  activation = 'relu',\n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 2nd max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "# # adding dropout\n",
    "# # model.add(Dropout(rate = .25))\n",
    "          \n",
    "# # Adding 3rd conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=3,\n",
    "#                  activation='relu',\n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 3rd max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "# # Adding 4th conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=3,\n",
    "#                  activation='relu', \n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 4th max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "# # Adding 5th conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=1,\n",
    "#                  activation='relu',\n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 5th max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "# # Adding 6th conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=1,\n",
    "#                  activation='relu',\n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# Adding 6th max pooling\n",
    "model.add(MaxPooling2D(pool_size= 4))\n",
    "\n",
    "# # Adding 7th conv layer\n",
    "# model.add(Conv2D(256,\n",
    "#                  kernel_size=1,\n",
    "#                  activation='relu',\n",
    "#                  kernel_regularizer = regularizers.l2(.01)))\n",
    "\n",
    "# # Adding 7th max pooling\n",
    "# model.add(MaxPooling2D(pool_size= 2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# model.add(Dense(256,\n",
    "#                activation = 'relu'))\n",
    "# model.add(Dense(128,\n",
    "#                activation = 'relu'))\n",
    "# model.add(Dense(64,\n",
    "#                activation = 'relu'))\n",
    "model.add(Dense(128,\n",
    "               activation = 'relu',\n",
    "               kernel_regularizer = regularizers.l2(.01)))\n",
    "model.add(layers.Dense(6, activation = 'softmax',\n",
    "                      kernel_regularizer = regularizers.l2(.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 220, 220, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 387200)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               49561728  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 49,638,150\n",
      "Trainable params: 49,638,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# checking summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "50/50 [==============================] - 392s 8s/step - loss: 4.2533 - acc: 0.2650 - val_loss: 2.1714 - val_acc: 0.2644\n",
      "Epoch 2/12\n",
      "50/50 [==============================] - 381s 8s/step - loss: 1.8452 - acc: 0.4819 - val_loss: 1.8528 - val_acc: 0.4293\n",
      "Epoch 3/12\n",
      "50/50 [==============================] - 371s 7s/step - loss: 1.6095 - acc: 0.5454 - val_loss: 1.8897 - val_acc: 0.3796\n",
      "Epoch 4/12\n",
      "50/50 [==============================] - 376s 8s/step - loss: 1.4886 - acc: 0.5763 - val_loss: 1.7178 - val_acc: 0.4555\n",
      "Epoch 5/12\n",
      "50/50 [==============================] - 374s 7s/step - loss: 1.4668 - acc: 0.5863 - val_loss: 2.0839 - val_acc: 0.3429\n",
      "Epoch 6/12\n",
      "50/50 [==============================] - 372s 7s/step - loss: 1.4346 - acc: 0.5556 - val_loss: 1.7194 - val_acc: 0.4162\n",
      "Epoch 7/12\n",
      "50/50 [==============================] - 377s 8s/step - loss: 1.3568 - acc: 0.6175 - val_loss: 1.7980 - val_acc: 0.4607\n"
     ]
    }
   ],
   "source": [
    "# fitting model\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=50,\n",
    "        epochs=12,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=12,\n",
    "        workers = -1,\n",
    "        verbose = 1,\n",
    "        callbacks = call_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_extractor = Model(model.input, outputs=model.get_layer(\"dense_2\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 220, 220, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 387200)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               49561728  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 49,638,150\n",
      "Trainable params: 49,638,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feat_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "# model.save('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 31s 6s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4364753246307373, 0.58125]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model performance\n",
    "model.evaluate_generator(train_generator, steps = 5, workers = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
